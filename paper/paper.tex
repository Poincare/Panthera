\documentclass[12pt]{article}

% The geometry package al	lows for easy page formatting.
%\usepackage{geometry}
%\geometry{letterpaper}

% Load up special logo commands.
\usepackage{doc}
\usepackage{fullpage}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{lmodern}

% Package for formatting URLs.
\usepackage{url}

% Packages and definitions for graphics files.
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{natbib}
\usepackage{tikz}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

%
% Set the title, author, and date.
%
\title{Panthera: Caching and Cache-based
Scheduling in Distributed Computing Systems}
\author{Dhaivat Pandya \\ Appleton North High School}
\date{}
%
% The document proper.
%
\begin{document}

% Add the title section.
\maketitle

% Add an abstract.
\abstract{
	The adoption of distributed computing systems has grown massively in the past few years. In particular, Apache Hadoop, which allows developers to create applications that run on a cluster of computers, is currently used throughout academia and industry in areas such as machine learning, medical diagnosis, natural language processing, etc. However, the Hadoop File System fails to effectively utilize random access memory (RAM) and local storage in order to reduce waiting time (i.e. latency). In this project, named \textit{Panthera}, caching and scheduling systems for Hadoop were developed. \textit{Panthera} caches both information about files and the file contents, thereby reducing waiting time in downloading and accessing the files and related information. It runs with an unmodified version of Hadoop, meaning it can integrate easily into existing architecture. The results showed that data access latency was 8.63 times lower with \textit{Panthera} and metadata access latency was 8.13 times lower. Such drastic decreases in latency can greatly increase the efficiency of existing Hadoop applications and also allow the creation of algorithms that were previously not feasible on Hadoop. \textit{Panthera} was tested with existing Hadoop algorithms and running times were up to 3.31 times lower than the control group of a standard Hadoop installation. In addition to the caching system, a scheduler and scheduling algorithm for Hadoop were developed. They use information available about the caches to decide the order of execution for computational jobs, thereby further reducing running time. Finally, \textit{Panthera} is widely applicable and can significantly speed up research in a very large range of fields ranging from bioinformatics to artificial intelligence. All code developed during this project will be open sourced to further development in the area.
}

\section{Introduction}
As computational problems and their associated datasets have grown in size, it has become necessary to take advantage of distributed computing systems to solve them \cite{taylor2010overview}. Such systems allow programs to scale from one computer (i.e. one \textit{node}) to thousands of computers with few or no changes in the codebase. In particular, the Hadoop distributed system \cite{hadoop} has seen tremendous growth. Hadoop is an open source version of the revolutionary MapReduce system developed at Google \cite{mapreduce}. With it, developers can easily take advantage of large, multi-node clusters to solve computational problems.

Current Hadoop deployments exist in the thousands of nodes at companies such as Cloudera, Facebook, Yahoo, etc. Especially in such large networks, \textit{access latency}, or the waiting time associated with accessing files through the Hadoop Distributed File System (\textit{HDFS}), is a significant concern. Latency in distributed systems can have significant effects and a reduction of the same comes with tremendous benefits. As the RAMCloud project has outlined \cite{ramcloud}, low latency can greatly extend the applications of distributed computing systems. For example, tree traversal algorithms are largely impractical in high latency systems such as Hadoop \cite{ramcloud}, however, with lowered latency, such algorithms may become useful and applicable. HDFS currently does not use local (i.e. on the client) random access memory (RAM) to improve latency.

In this paper, I present \textit{Panthera}, a \textit{cache layer} and \textit{cache-based scheduling system} for Hadoop. The \textit{Panthera} cache layer functions by retaining recently accessed files in random access memory, thus, when the files are needed once again, they do not have to be downloaded or read from the hard drive, thereby greatly reducing file access latency. Another portion of the project, the \textit{Panthera} scheduling system utilizes information about the data blocks cached in a cluster at a given time to schedule jobs. By doing so, it aims to maximize the benefit of caching to a series of jobs.

In this paper, we discuss both the \textit{Panthera} caching layer and scheduling system. In Section 2, we discuss the specific challenges associated with such a project. Section 3 details the architecture differences between a standard Hadoop installation and one with \textit{Panthera}.  Sections 4 and 5 detail the differences between metadata and data caching within \textit{Panthera}. Results and conclusions are covered in Sections 6, 7, 8, 9, concluding with a roadmap for future development in Section 10.

\section{Design Constraints}

There are several systems built on Hadoop that are in widespread use \cite{hbase, cloudbatch, pig}. The Hadoop project is also supported by large corporations with a 
consistent release cycle. Thus, for \textit{Panthera} to be practical, it must operate independently of the existing Hadoop codebase, i.e. as a layer, rather than modification. This implies that \textit{Panthera} must implemented without a single change in the existing Hadoop codebase, i.e. as a "drop-in" solution. Additionally, for non-cache related requests, \textit{Panthera} must add insignificant latency. Finally, data and metadata request latency should be significantly lowered with \textit{Panthera} in comparison to a standard Hadoop installation. 

In order to develop a cache-based scheduling system, the \textit{Panthera} caching layer must be able to report information (e.g. blocks currently cached) over the network. The cache-based scheduler then uses information about blocks cached and the files each job requires to run in order to optimize the running order of a set of jobs (see Section \ref{scheduler-section} for a complete description of the \textit{Panthera} scheduling algorithm).

\section{Metadata and Data}

Within the Hadoop File System (HDFS), there is a clear distinction between \textit{metadata} and \textit{data} \cite{hdfs}. Metadata refers to information about a file or a directory, e.g. file size, file names, on which server the contents of a file are located, etc. For HDFS, the NameNode server handles all metadata. For every request, the NameNode recomputes metadata. \textit{Panthera} can reduce this computation by caching the results of a previous request, thereby conserving resources.

Data refers to the actual content of a file. Within HDFS, each file is split into 64 MB large \textit{blocks}, which are stored on DataNodes. Here, \textit{Panthera} serves to reduce access time by holding recently used blocks in RAM locally thereby eliminating the need to download files from a remote server if they are present in the cache.

Metadata and data caching provide significantly different technical challenges as the former involves conversion of computational latency to memory latency, whereas the latter involves a conversion of network and hard drive latency to memory latency. Note: memory latency is of the smallest magnitude of all three in consideration. In many cases \cite{ramcloud} it is 1/1000th hard drive latency.

\section{Architecture}
\begin{figure}[!h]
	\centering
	\includegraphics[scale=0.4]{assets/hadoop_architecture.pdf}
	\includegraphics[scale=0.4]{assets/panthera_architecture.pdf}
  \caption{Standard Hadoop Architecture (left), \textit{Panthera}-Hadoop Architecture (right)}
  \label{arch}
  
\end{figure}

Figure~\ref{arch} outlines the architecture differences between a standard Hadoop File System architecture and an installation with \textit{Panthera}. In HDFS, the \textit{NameNode} serves as a metadata server, handling all requests from clients relating to metadata (e.g. directory listing, file sizes, block locations, etc.). \textit{DataNode(s)} hold data and serve it at request from the client. A more complete description of the Hadoop File System may be found in \cite{hadoop}.

\textit{Panthera} operates by intercepting requests and responses at the NameNode and the client. Both nodes have a running instance of \textit{Panthera}. Every request issued from the client is first reviewed by \textit{Panthera}, and if possible, answered immediately from the cache. The \textit{Panthera} instance on the NameNode constantly monitors the filesystem for changes that need to be reflected in the cache (e.g. if a file is deleted, the cache on the client should not have a copy of it).

\textit{Panthera}, since it caches both data and metadata, can be considered two separate subsystems, which are now discussed.

\section{Metadata caching}

\begin{figure}[!h]
	\caption{\textit{Panthera} Metadata System}
	\centering
		\includegraphics[scale=0.4]{assets/panthera_meta_architecture.pdf}
\end{figure}

The \textit{Panthera} metadata system runs on the NameNode and communicates with the \textit{Panthera} instance on the client. The challenge on the metadata portion consist of reducing computational latency to memory latency. For example, for some intensive methods (e.g. a recursive directory listing), it may be worthwhile to cache a response in order to prevent computing the same list again.

However, the problem lies in identifying such methods. Obviously, there are some methods for which caching is not worthwhile since their execution time is lower or comparable to memory latency. Within \textit{Panthera}, six different Hadoop query methods were identified as medium to high latency. \textit{Panthera} identifies packets that contain these methods and subsequently caches them.

Currently, a standard LRU cache \cite{cache} is used for each method. Testing of different caching methods and predictive prefetching algorithms is under way.

\section{Data caching}

\begin{figure}[!h]
	\caption{\textit{Panthera} Data System}
	\centering
		\includegraphics[scale=0.4]{assets/panthera_data_architecture.pdf}
\end{figure}

\textit{Panthera}'s data caching system runs on the client. The architecture is similar to that of the metadata caching system. Every request that the client makes to the DataNodes is first processed by \textit{Panthera} and responded to from the cache if possible. 

The challenges with data caching differ significantly from those in metadata caching. Here, the goal is to convert network and hard drive read latency into memory latency. As \cite{ramcloud, hadoop} note, memory latency can be extremely low in modern systems, especially in comparison to network and hard drive latencies. Thus, in some respects, the goal of lowered latency is "easier" to attain in the data cache. However, for smaller files, it may be difficult to obtain latency improvement.

Hadoop, in professional and academic environments, is often used with series rather than individual jobs. Deciding how to order these jobs depending on cached file availability is a problem of great interest; \textit{Panthera} presents the solution of a cache-based scheduler for Hadoop.

\section{Scheduling Algorithm} \label{scheduler-section}

The scheduling problem faced may be stated as: 

\begin{quote}
Given $\mathbf{J} = J_1, J_2, ... ,J_k$ jobs to be run on a Hadoop cluster with caches $\mathbf{C} = C_1, C_2, ..., C_n$, what ordering will best take advantage of the caches?
\end{quote}

Each $J_i$ accesses a set of blocks $F_i$ and each $C_i$ holds a set of blocks $B_i$. \textit{Panthera} assigns every $J_i$ a \textit{job score}, denoted $x_i$:
			\begin{equation}
				x_i = \displaystyle{\frac{\left\vert{F_i \cap B_t}\right\vert}{ \left\vert{B_t}\right\vert}} \; \textrm{where} \;
				B_t = \bigcup_{j = 1}^{n} B_j
			\end{equation}
			
			The \textit{Panthera scheduling algorithm} consists of sorting $\mathbf{J}$ in descending order with respect to the $x_i$ associated
			with each $J_i$. 
			
		While $J_i$ is running, \textit{Panthera} may prefetch data for $J_{i+1}$ to further reduce latency. An implementation of predictive prefetching algorithms as described in \cite{griffioen1994reducing} is possible in \textit{Panthera} and may serve to further reduce latency in specific applications.
		
\section{Testing Methodology}

In order to test the metadata cache, a directory listing query was repeatedly run on a directory with 100 files in it, and the latency times for responding are measured, with \textit{Panthera} and without. The reasoning for picking such a test lies in the fact that a directory listing in Hadoop involves all six of the cached methods as well as a few non-cached methods. Thus, the test provides a good estimate of the efficacy of the cache. Latency times for the data cache were obtained by repeatedly querying for a 64 megabyte large file. The file size was chosen since it is the default block size for a Hadoop cluster and the \textit{Panthera} cache stores files as blocks. Both metadata and data cache testing was conducted on virtualized server instances running on hardware with solid state hard drives. 

In order to test the effects of \textit{Panthera} on the Hadoop computing system (rather than focusing on only HDFS access time), running times of two existing algorithms were recorded. The first is \textit{WordCount}, the classic distributed algorithm that counts the number of occurrences of each word in a text file. The second has been, termed \textit{RefCount}, has thus far been impractical on Hadoop due to excessive running times. It is similar to WordCount in that it counts occurrences of words, but it consults a \textit{reference file} (e.g. a limited dictionary) to determine which words are to be counted.

\section{Results}
\begin{figure}
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[scale=0.3]{assets/v2/getter_boxplot.pdf}
  \caption{Data access latency}
  \label{data}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[scale=0.3]{assets/v2/multinode_meta_box_plot.pdf}
  \caption{RefCount job performance}
  \label{meta}
\end{subfigure}
\caption{Metadata access latency}
\label{fig:test}
\end{figure}


	\begin{table}
	\centering
			\begin{tabular}{lcc}
			\toprule
			\textbf{Type} & \textbf{Mean Time Improvement} & \textbf{Standard Dev. Contraction} \\
			\midrule
			Metadata   & 8.13x & 27.38x \\
			Data       & 8.63x & 11.14x \\
			WordCount & 1.25x & \phantom01.02x \\
			Ref. count & 3.31x & 22.91x \\
			\bottomrule
			\end{tabular}
		\caption{Latency improvement with \textit{Panthera}}
		\label{results}
	\end{table}

	
The \textit{Panthera} data cache decreased file access latency by a factor of 8.63 and metadata access latency was lowered by a factor of 8.13, both representing drastic decreases in HDFS latency. In addition, the standard deviation was also significantly decreased with \textit{Panthera}: by a factor 27.38 for metadata and a factor of 11.14 for data. With a lower standard deviation, the predictability of performance for Hadoop applications increases.

The tests with existing Hadoop algorithms show similarly positive results. \textit{Panthera} is able to reduce running time for the WordCount algorithm by 25\% and is able to do the same for the Ref. Count algorithm by 331\%. It is important to keep in mind that these performance boosts were attained with the original algorithms left entirely unmodified. The difference between the two lies in the fact that WordCount has little interaction with HDFS once the initial input files have been downloaded, whereas Ref. Count often obtains the reference file from HDFS. Notice that the testing was conducted with only one slave node. Adding slave nodes to a cluster would increase the number of file requests since each node requires a portion of the input file. 

\begin{figure}
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[scale=0.3]{assets/v2/wordcount_boxplot.pdf}
  \caption{WordCount job performance}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[scale=0.3]{assets/v2/refgetter_boxplot.pdf}
  \caption{RefCount job performance}
  \label{refgetter}
\end{subfigure}
\caption{Algorithm running time comparison}
\label{fig:test}
\end{figure}

\section{Conclusion}

\textit{Panthera} fulfils all of the constraints mentioned at the outset. It is a layer on Hadoop rather than a main repository code modification, allowing existing Hadoop applications to remain entirely unmodified. Considering the latency measurements, it is clear that it has also met the requirements in terms of benefit. \textit{Panthera} was able to reduce data access latency by a factor of 8.63 and reduce basic metadata access latency by 8.13. Also, \textit{Panthera} was able to minimize the spread of latency times in both data and metadata requests. Thus, \textit{Panthera} opens up great possibilities within Hadoop due to the fact that algorithms that were previously impractical (e.g. distributed tree traversal algorithms) may now be implemented. Additionally, a scheduler algorithm was devised and a cache-based scheduler was implemented for Hadoop which enables further reduction of latency via greater utilization of cached resources.

Previous work \cite{hdfs, borthakur2011apache} has lamented the latency issues that have plagued HDFS and Hadoop as barriers to adoption. \textit{Panthera} significantly reduces the scope of these issues and allows the application of Hadoop in areas where its reach has been limited.

\section{Applications}
One of the major benefits of the systems developed is that they are independent of the existing Hadoop codebase and they do not require modifications to existing Hadoop applications. Thus, \textit{Panthera} may be deployed in a wide range of scenarios, such as the following:

\begin{itemize}
	\item Bioinformatics: Hadoop is currently in use in bioinformatics research \cite{taylor2010overview}. Panthera can be employed to reduce access latencies of various datasets, e.g. protein data banks, etc. Additionally, domain-specific prefetching can be performed to further improve performance.
	
	\item Machine learning: Apache Mahout is a machine learning library for Hadoop. Panthera has been tested with the K-Means implementation it provides and there is evidence of significant performance improvement.
	
	\item Predictive analytics: A quickly growing field that has thoroughly
	embraced Hadoop \cite{chen2012business}. Metadata caching can be used to decrease human operator waiting time. Often, queries consist of several queued jobs, meaning that the \textit{Panthera} scheduler can be used to optimize
	job ordering.
\end{itemize}

\section{Future work}
One of the most immediate avenues for further research is in \textit{domain-specific prefetching}. Different problem domains (e.g. natural language processing, predictive analytics, etc.) have different dataset requirements. It may be possible to predict what files a given job will need depending
on what problem domain the job is in. A generalized version of the same problem would be \textit{predictive prefetching} \cite{griffioen1994reducing} which involves the prediction and prefetching of files that will be required in the future. In both these problems, the Hadoop environment provides unique
challenges.


Another area worthy of further exploration is the effect of different cache replacement algorithms in Hadoop. Though various cache replacement algorithms
have been explored thoroughly at the local filesystem level, their study 
in conjunction with existing Hadoop algorithms may provide novel results, i.e.
the access patterns of certain procedures may work best with a certain
cache replacement scheme \cite{puzak1985analysis}.

\nocite{*}

\bibliographystyle{plain}
\bibliography{references}

\end{document}